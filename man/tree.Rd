% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tree.R
\name{tree}
\alias{tree}
\title{Create Classification 'tree' Object}
\usage{
tree(formula, data, m, minsplit = 20, minbucket = round(minsplit/3),
  maxdepth = 30)
}
\arguments{
\item{formula}{A \code{formula} containing variable names of response and
predictors.}

\item{data}{data.frame of data to fit the model on.}

\item{m}{Size of predictor subset. If \code{m} is chosen smaller than the
number of predictors, a random subset of the specified predictors will be
used for tree construction.}

\item{minsplit}{Minimum number of observations needed for a split.}

\item{minbucket}{Minimum number of observations that need to be contained
each of the left and right groups after a node was split.}

\item{maxdepth}{Maximum tree depth. The root node has \code{depth = 0}, so
that \code{maxdepth = 3} constrains the tree to 4 levels.}
}
\value{
An object of class \code{tree}, containing the following elements:
A \code{root} node, which holds the tree structure. A list of \code{names}
for response and predictor names as well as response classes (NOTE: The
element \code{predictors} holds the names of ALL predictors, even if some
were in fact not used as specified by parameter \code{m}). \code{frequencies}
holds the root's response class frequencies. \code{importance} holds a
ranking of predictor importance, measured by the mean information gain.
\code{control} holds the options as specified in the function call, as well
as \code{random = FALSE} if all predictors were considered for tree
construction.)
}
\description{
Creates a fitted classification \code{tree} model.
}
\details{
Note on variable \code{importance}: \code{meanGain = 0} means that
this predictor was taken into account by the tree building process but was
not used, since it did not yield information gain.\code{meanGain = NA} means
that this predictor was specified in \code{formula} but randomly dropped out
of consideration due to the choice of \code{m} (random predictor subset).
}
\examples{
# Sample split
data <- iris
set.seed(1337)
rows <- sample.int(nrow(data), size = floor(0.7*nrow(data)), replace = FALSE)
trainData <- data[rows,]
testData <- data[-rows,]
# Create fitted 'tree' object
fit <- tree(Species ~ .,
            data = trainData,
            m = 4,
            minsplit = 20,
            minbucket = 5,
            maxdepth = 3)
}
